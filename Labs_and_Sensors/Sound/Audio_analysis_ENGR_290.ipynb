{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"163sZlsdw3ffkMTF1ZlYQBanCKAeXwdLh","timestamp":1681334803348},{"file_id":"16JITiENZU-7uDzGgiu0lWSWzy3Y1Uugq","timestamp":1681187524827}],"mount_file_id":"1jBiba8SCuQIrpSgpahIkNFIhSWCVaUja","authorship_tag":"ABX9TyMDeMT8NNJ/Z5cq2y27w37S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Fast Fourier Transform\n","\n","This notebook does the following:\n","* imports a .wav audio file\n","* displays the signal in the time domain\n","* converts the signal into the frequency domain\n","* filters the signal in the frequency domain\n","* convert the signal back into the time domain and displays it. <br> <br>\n","\n","This is pretty neat ðŸ˜€  Hope you enjoy it! (And thanks to Dr. Van Howe for his help!)  <br><br>\n","\n","---\n","\n"],"metadata":{"id":"1ysb3_XkZWJn"}},{"cell_type":"markdown","source":["### Import the audio file\n","\n","The first couple cells import some needed libraries, and then import the audio file from your Google drive.  Change the `filename` in the third cell to define the folder from which you are importing.  This will take a couple minutes to run."],"metadata":{"id":"1ogWrjEzaVfO"}},{"cell_type":"code","source":["#import libraries needed\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.io import wavfile\n","import scipy.io.wavfile as wavf\n","from IPython.display import Audio\n","from scipy.fft import fft, ifft, fftshift,rfft,ifftshift"],"metadata":{"id":"bUVSvuB-x2Va"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Grant Colab acces to your google drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"YgUae2kRxVJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read an audio wavfile\n","# Replace the file address here with the appropriate address\n","filename = '/gdrive/MyDrive/Teaching/Engr_290/Notebooks_290/Labs_and_Sensors/Sound/C_trumpet_E4.wav'\n","rate, audio = wavfile.read(filename)"],"metadata":{"id":"bUtDA7jnoC4m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We've imported a file that contains the sound of a trumpet playing a middle E.  Take a listen!"],"metadata":{"id":"uPDscawWGUje"}},{"cell_type":"code","source":["wavf.write('audin.wav', rate, audio)\n","Audio('audin.wav')"],"metadata":{"id":"er5GsqTvGC39"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that this audio file is a discretized wave signal: that is, it is an array of data that represents the amplitude of the wave at different moments in time.  In other words, it's just a one-dimensional list of numbers.  Here we can see the first 100 elements:"],"metadata":{"id":"AaYEMX2VIeG7"}},{"cell_type":"code","source":["print(audio[0:100])"],"metadata":{"id":"eED-AO1EG17Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Display the signal in the time domain\n","\n","Let's take a closer look at the discretized version of this signal.  To do so, we want to define and prints out some key information about the file:"],"metadata":{"id":"ItXEeBWlatv-"}},{"cell_type":"code","source":["# Define the length of the array\n","N = len(audio)\n","\n","# The sampling rate 'rate' is determined when the audio file\n","# is recorded; here that is converted into the time step size 'dt'\n","dt = 1/rate\n","\n","# Define the total time and the frequency resolution\n","total = N/rate\n","df = 1/total\n","\n","# This makes an index that goes from -half the pts to +half the pts in the audio file\n","# The center is 0 now, and this makes the math for the FFT work better\n","# This is then transformed into arrays for time and frequency\n","x = np.linspace(-N/2,N/2-1,N)\n","time = dt*x\n","freq = df*x\n","\n","# Print out the key values\n","print(\"N = \", N)\n","print(\"Rate = \", rate)\n","print(\"Dt = \",  dt)\n","print(\"Total = \",  total)\n","print(\"df = \",  df)"],"metadata":{"id":"H_aVGL07nIYj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… âœ… Before going on, answer the \"Set 1\" questions on the worksheet."],"metadata":{"id":"L5Zy2Esx9sQo"}},{"cell_type":"code","source":["# plot the audio file as the waveform\n","plt.figure()\n","plt.plot(time, audio)\n","plt.xlabel('Time (s)')\n","plt.ylabel('Amplitude)');\n","# The next line changes the range of the x-axis\n","# Uncomment and change the arguments to zoom in on the signal\n","plt.xlim(0,0.01);\n"],"metadata":{"id":"mVMz5U5600or"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… âœ… Before going on, answer the \"Set 2\" questions on the worksheet."],"metadata":{"id":"7jSWcnJd_E1g"}},{"cell_type":"markdown","source":["### Convert the signal to the frequency domain\n","\n","In the time domain, the x-axis is in units of time.  The FFT transforms the signal--much like changing a coordinate system--so that the x-axis is in units of frequency.  This allows us to see which frequency sine waves are added together to get the complex signal that we started with."],"metadata":{"id":"1x8B8gWlcBQJ"}},{"cell_type":"code","source":["#  Now we'll do some Fourier magic!!!\n","yf=fftshift(fft(audio))\n","\n","# Plot the Fast Fourier Transform (FFT)\n","# Each spike represents a sine wave\n","plt.figure()\n","plt.plot(freq, abs(yf))\n","plt.xlabel('Frequency (Hz)')\n","plt.ylabel('Amplitude)')\n","# Change the line below to zoom in on relevant data\n","plt.xlim(0,5000);"],"metadata":{"id":"JhyuytajQG_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… âœ… Before going on, answer the \"Set 3\" questions on the worksheet."],"metadata":{"id":"amVBl_LpAmpf"}},{"cell_type":"markdown","source":["### Filtering the signal in the frequency domain\n","\n","Filtering in the frequency domain is pleasingly simply: all we need to do is multiply the frequencies that we want to keep by 1.0, and the frequencies that we want to filter by 0.   We'll set this up so that it can be a low-pass or a high pass filter. <br><br>\n","\n","You only need to change the variables in this first cell to control the filter:"],"metadata":{"id":"BQoVhrlNdaVi"}},{"cell_type":"code","source":["# Define whether you want a high pass or low pass filter.\n","# If you want a high pass filter, define 'hipass' as 1;\n","# for a low pass filter, define it as zero\n","hipass = 0\n","\n","# Define the cutoff frequency (in Hz)\n","cutoff = 500"],"metadata":{"id":"xIAdwepy4FIy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We're going to make an array that includes only 1s and 0s that is the same size as the frequency domain audio file.   By multiplying that file element-wise with this array, we will keep some frequencies and eliminate others.  The image shows how element-wise multiplication works between two arrays:\n","\n","<img src = https://github.com/AugustanaPEA/ENGR_290/raw/main/Images/Element_wise_mult.PNG width = 300>"],"metadata":{"id":"8R0KZH2re0Qf"}},{"cell_type":"code","source":["# Convert the cutoff frequency from Hz to #pts in the array\n","edge = cutoff/df\n","\n","# Define the data points that are inside the filter\n","# There is a high and a low cutoff because the FFT produces\n","# positive and negative frequencies (that mirror each other)\n","range_lo=round(N/2-edge)\n","range_hi=round(N/2+edge)\n","\n","# Now we make our filter array, depending on the value of 'hipass'\n","if hipass == 1:\n","    yfilt=np.ones(len(freq))\n","    yfilt[range_lo:range_hi]=0\n","else:\n","    yfilt=np.zeros(len(freq))\n","    yfilt[range_lo:range_hi]=1"],"metadata":{"id":"2e22izJvevwk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we'll plot out the FFT with a red line showing us which frequencies will be kept and which will be filtered out:"],"metadata":{"id":"udbcJidxgTmW"}},{"cell_type":"code","source":["# Plot the FFT and the filter window\n","# to see if our filter is in the correct place\n","plt.figure()\n","plt.plot(freq, abs(yf))\n","plt.plot(freq,yfilt*max(abs(yf)),'-r')\n","plt.xlabel('Frequency (Hz)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(0,2000);"],"metadata":{"id":"NoCWYHf4gSfP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we'll multiply the full frequency spectrum `yf` by the filter array in order to get a new filtered spectrum called `yfnew`.  The plot shows the spectrum of the filtered signal: we've removed the frequencies either above or below the cutoff frequency:"],"metadata":{"id":"kwin6Z3egf5W"}},{"cell_type":"code","source":["###time to do the filtering, just a simple multiplication in the freq domain\n","yfnew=yf*yfilt\n","\n","###plot filtered spectrum; should be just what we let in\n","plt.figure()\n","plt.plot(freq, abs(yfnew))\n","plt.plot(freq,yfilt*max(abs(yfnew)),'-r')\n","plt.xlabel('Frequency (kHz)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(0,2000);"],"metadata":{"id":"JC5JcYQK4NML"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… âœ… Before going on, answer the \"Set 4\" questions on the worksheet."],"metadata":{"id":"9iHmkaY2KMGR"}},{"cell_type":"markdown","source":["### Convert the signal back to the time domain\n","\n","Finally, we want to see what the filtered signal looks like as a wave.  So we use the Inverse Fast Fourier Transform: this converts our frequency domain description of the filtered wave (that is, the plot just above this cell) into a time-domain description of the signal. <br><br>\n","\n","To be able to see what the filter did to the signal, the filtered signal is printed over the unfiltered signal.  Play with the filter parameters to see the effect of different filters!"],"metadata":{"id":"YFIWuYz9gtYe"}},{"cell_type":"code","source":["####transform back into time domain with inverse fft or ifft\n","yt=ifft(ifftshift(yfnew))\n","\n","\n","###Filtered wav in time domain\n","plt.figure()\n","plt.plot(time, np.real(yt),'-r')\n","plt.plot(time, audio, '--')\n","plt.xlabel('Time (s)')\n","plt.ylabel('Amplitude)')\n","plt.legend([\"Filtered Signal\", \"Unfiltered Signal\"], loc =\"upper right\")\n","# Play with the line below to zoom in or out\n","plt.xlim(0,0.01);"],"metadata":{"id":"cLhMuuOI49vV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can see the difference between the filtered and unfiltered signal, but you can also *hear* that difference if we convect the filtered signal back into an audio `.wav` file:"],"metadata":{"id":"Fc7djGNjLzCj"}},{"cell_type":"code","source":["# 'yt' is actually an array of complex numbers; we just want the real part\n","audiout=np.real(yt)\n","\n","# Now we can convert the file back into a .wav file and play it\n","audiout=np.asarray(audiout, dtype=np.int16)\n","wavf.write('audiout.wav', rate, audiout)\n","Audio('audiout.wav')"],"metadata":{"id":"9-F0gRGpihRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now compare it to the original unfiltered signal\n","Audio('audin.wav')"],"metadata":{"id":"BTHDx5ZpNAGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["âœ… âœ… Now play with the filter a bit, and answer \"Set 5\"."],"metadata":{"id":"T1V757kdNUTN"}}]}