{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1jBiba8SCuQIrpSgpahIkNFIhSWCVaUja","authorship_tag":"ABX9TyMDIla3y5Ez3YWBQcZKS3+5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["###import libraries needed\n","\n","from scipy import signal \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.fft import fft, ifft, fftshift\n","from scipy.io import wavfile\n","import scipy.io.wavfile as wavf\n","!pip install playsound\n","from playsound import playsound"],"metadata":{"id":"bUVSvuB-x2Va"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import audio wavfile\n","# Replace the file address here with the appropriate address for your Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')\n","filename = '/gdrive/MyDrive/Colab Notebooks/C_trumpet_E4.wav'\n","rate, audio = wavfile.read(filename) ###reads in trumpet, rate = sampling rate in Hz, audio is the y values\n","\n","# Set and check parameters for audio\n","N = audio.shape[0]  ###gives the length of the array\n","\n","dt=1/rate  ### in sec, basically the definition of sampling rate, the higher, the smaller the dt, the more freqs (better quality) the sound (although there is no need for the rate to be > 2*20,000 Hz since our ears can't hear above 20,000; the 2 has to do with Nyquist sampling theorem)\n","x=np.linspace(-N/2,N/2-1,N)  ### make an index that goes from -half the pts to +half the pts; center is 0 now\n","totaltime=N/rate  ##in sec\n","df=1/totaltime   ###in Hz, important FFT relation when defining Fourier variables: dt=1/totalf, df=1/totaltime, df = totalf/N, dt= totaltime/N\n","time=dt*x  ##makes an array of elapsed time, centered at 0\n","freq=df*x  ##Makes an array of frequency offset, centered at 0\n","\n","print(\"Number of data points = \", N)\n","print(\"Frequency = \", rate)\n","print(\"Dt = \",  dt)\n","print(\"Total time = \",  totaltime)\n","print(\"df = \",  df)"],"metadata":{"id":"YgUae2kRxVJx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the audio file as the waveform\n","plt.figure()\n","plt.plot(time, audio)\n","plt.xlabel('Time (s)')\n","plt.ylabel('Amplitude)')\n","# Uncomment the line  below and play with this to see inside the envelope, make this range smaller\n","#plt.xlim(-3,3)  "],"metadata":{"id":"mVMz5U5600or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the spectrogram function\n","\n","M=1024  ###takes slices of 1024 pts to FFT\n","freqs, times, Sx = signal.spectrogram(audio, fs=rate, window='hanning',\n","                                      nperseg=1024, noverlap=M - 100,\n","                                      detrend=False, scaling='spectrum')\n","\n","\n","####cuts up audio into 1024 slices and stores them in a 3D structure: freqs, times, and Sx (which is the strength), then overlaps the edges by 100 pts and smooths the edges with a Hanning window so not choppy\n","\n","###alternative plot commands for a surface plot\n","f, ax = plt.subplots(figsize=(4.8, 2.4))\n","ax.pcolormesh(times, freqs / 1000, 10*np.log10(Sx), cmap='viridis')\n","ax.set_ylabel('Frequency [kHz]')\n","ax.set_xlabel('Time [s]');\n","\n","plt.ylim(0,5)\n"],"metadata":{"id":"f8YtS01T3uXS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###now let's do some Fourier magic!!!\n","\n","# #######Taking Fourier transform of entire file shows the frequencies present for the entire duration of the clip ~7 seconds\n","yf=fftshift(fft(audio))\n","\n","####plot FFT, each spike represents a sine wave; if a spike is negative, that has to do with the phase of that sinewave component\n","plt.figure()\n","plt.plot(freq/1000, yf)    ###dividing by 1000 here makes the scale kHz\n","plt.xlabel('Frequency (kHz)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(-2,2);"],"metadata":{"id":"uoKqADaD36xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####make simple LPF\n","####Because I am using FFt (operates in complex space) we have both positive and negative freqs\n","####an LPF  is going to be what we drew on wavepad, but reflected about the zero, HPF will just be the flip of the LPF (1's go to 0's, 0's go to 1's)\n","\n","# ####filter\n","yfilt=np.zeros(len(freq)) ###just makes an array of all zeros that's the sam length as signal\n","fedge =500  ### edge of low pass in Hz\n","edge=fedge/df   ####converts real freqs to  #pts in the array so python knows what I mean by 500 Hz\n","rangelo=round(N/2-edge) ##fedge Hz lower than middle\n","rangehi=round(N/2+edge) ###fedge Hz higher than middle\n","yfilt[rangelo:rangehi]=1  ###takes the array of all zeros and puts 1's now from rangelo to rangehi\n","\n","####replot FFT and the filter function to see if we matched what we wanted\n","\n","plt.figure()\n","plt.plot(freq/1000, yf/max(yf)) #now Im normalizing spectrum so we can see the filter function on the same plot/scale\n","plt.plot(freq/1000,yfilt,'-r')\n","plt.xlabel('Frequency (kHz)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(-2,2);"],"metadata":{"id":"xIAdwepy4FIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###time to do the filtering, just a simple multiplication in the freq domain\n","yfnew=yf*yfilt\n","\n","###plot filtered spectrum; should be just what we let in\n","plt.figure()\n","plt.plot(freq/1000, yfnew/max(yfnew))\n","plt.plot(freq/1000,yfilt,'-r')\n","plt.xlabel('Frequency (kHz)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(-2,2);"],"metadata":{"id":"JC5JcYQK4NML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####transform back into time domain with inverse fft or ifft\n","yt=ifft(fftshift(yfnew))\n","\n","###Filtered wav in time domain\n","plt.figure()\n","plt.plot(time, np.real(yt),'-r')\n","plt.plot(time, audio, '--')\n","plt.xlabel('Time (s)')\n","plt.ylabel('Amplitude)')\n","plt.xlim(0,0.02)   #Zoom up of before and after; play with this range to look at the wave"],"metadata":{"id":"cLhMuuOI49vV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsXsbOnVujyL"},"outputs":[],"source":["# Spectogram of the filtered wave\n","\n","audiout=np.real(yt)   ### our yt was actually complex, just take real part\n","audiout=np.asarray(audiout, dtype=np.int16)  ###this helps convert it to int16 so we can write back to .wav\n","\n","\n","####Spectrogram Filtered wave\n","M=1024  ###takes slices of 1024 pts to FFT\n","freqs, times, Sx = signal.spectrogram(audiout, fs=rate, window='hanning',\n","                                      nperseg=1024, noverlap=M - 100,\n","                                      detrend=False, scaling='spectrum')\n","\n","\n","####cuts up audio into 1024 slices and stores them in a 3D structure: freqs, times, and Sx (which is the strength), then overlaps the edges by 100 pts and smooths the edges with a Hanning window so not choppy\n","\n","###alternative plot commands for a surface plot\n","f, ax = plt.subplots(figsize=(4.8, 2.4))\n","ax.pcolormesh(times, freqs / 1000, 10*np.log10(Sx), cmap='viridis')\n","ax.set_ylabel('Frequency [kHz]')\n","ax.set_xlabel('Time [s]');\n","\n","plt.ylim(0,5)\n","\n","###finally, write wav to playable file\n","wavf.write('audin.wav', rate, audio) ###writes input in format python playsound can play, redundant\n","wavf.write('audiout.wav', rate, audiout) #we killed a lot of energy so may need to crank it up\n","\n","###uncomment and run in command line or with f9 to play sound in python (no need to use vlc, or mediplayer, etc)\n","#playsound('audin.wav')\n","#playsound('audiout.wav'"]}]}